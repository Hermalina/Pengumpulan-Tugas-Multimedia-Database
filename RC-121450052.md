**Hermalina Sintia Putri\
121450052\
RC**\
Three Ways of Storing and Accessing Lots of Images in Python\
https://realpython.com/storing-images-in-python/

CIFAR-10. CIFAR-10 adalah kumpulan data yang disediakan oleh Institut Kanada untuk Penelitian Lanjutan (Canadian Institute for Advanced Research). Dataset ini terdiri dari 60.000 gambar berukuran 32x32 piksel yang berwarna, dan setiap gambar termasuk dalam kelas objek yang berbeda, seperti anjing, kucing, dan pesawat terbang.

Untuk memuat dataset ini, kita dapat mengunduhnya dari tautan yang disediakan di artikel. Setelah diunduh dan di-zip, kita akan menemukan bahwa file-file tersebut bukanlah file gambar yang dapat dibaca manusia. Sebaliknya, file-file ini telah diserialkan dan disimpan dalam batch menggunakan cPickle.

Kode berikut mengunpickle setiap dari lima file batch dan memuat semua gambar ke dalam array NumPy:


```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/Hermalina/Documents/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

    Loaded CIFAR-10 training set:
     - np.shape(images)     (50000, 32, 32, 3)
     - np.shape(labels)     (50000,)


Setelah berhasil memuat semua gambar ke dalam variabel images beserta metadata mereka dalam variabel labels, langkah selanjutnya adalah menyiapkan environment untuk menyimpan dan mengakses gambar-gambar tersebut dari disk. Kita akan menggunakan Pillow untuk memanipulasi gambar, menginstalnya dengan perintah:


```python
! pip install Pillow
```

    Requirement already satisfied: Pillow in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (10.3.0)


    
    [notice] A new release of pip is available: 23.0.1 -> 24.0
    [notice] To update, run: python.exe -m pip install --upgrade pip


Setelah menginstal Pillow, maka akan siap untuk menyimpan dan membaca gambar dari disk. Selanjutnya, kita akan memulai dengan LMDB. LMDB digunakan untuk bekerja dengan Lightning Memory-Mapped Database yang berguna untuk penyimpanan dan pengambilan data dalam skenario dimana akses ke memori harus dilakukan secara cepat. Kita dapat menginstal LMDB Python binding dengan perintah:


```python
! pip install lmdb
```

    Requirement already satisfied: lmdb in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (1.4.1)


    
    [notice] A new release of pip is available: 23.0.1 -> 24.0
    [notice] To update, run: python.exe -m pip install --upgrade pip


Terakhir, kita akan memulai dengan HDF5. HDF5 adalah format file Hierarchical Data Format yang digunakan untuk menyimpan data ilmiah secara efisien. Dapat menginstalnya dengan perintah:


```python
! pip install h5py
```

    Requirement already satisfied: h5py in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (3.11.0)
    Requirement already satisfied: numpy>=1.17.3 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from h5py) (1.26.4)


    
    [notice] A new release of pip is available: 23.0.1 -> 24.0
    [notice] To update, run: python.exe -m pip install --upgrade pip


## Storing a Single Image

Untuk mempersiapkan perbandingan kinerja antara tiga metode penyimpanan yang berbeda, yaitu menggunakan file .png, menggunakan LMDB, dan menggunakan HDF5, kita akan membuat folder untuk setiap metode penyimpanan. Setiap folder akan berisi semua file database atau gambar yang sesuai. Kita dapat menggunakan modul 'path' dalam Python untuk membuat dan mengelola jalur ke folder-folder tersebut.

Berikut adalah langkah-langkahnya:

1. Import modul 'path' dari pustaka 'pathlib' untuk mengelola jalur file.
2. Buat tiga folder terpisah untuk setiap metode penyimpanan: satu untuk file .png, satu untuk LMDB, dan satu untuk HDF5.
3. Simpan semua file database atau gambar yang diperlukan ke dalam masing-masing folder yang sesuai.

Berikut contoh kode untuk melakukan hal ini:


```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```


```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

## Storing to Disk

Kita ingin menyimpan gambar yang saat ini ada di dalam memori sebagai array NumPy ke dalam disk sebagai gambar .png. Untuk melakukannya, kita menggunakan paket Pillow yang telah diinstal sebelumnya. Langkah-langkahnya adalah:


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

Kita perlu menyimpan gambar ke disk sebagai file .png dengan nama yang unik menggunakan ID gambar (image_id). Kita dapat menggunakan paket Pillow untuk melakukan ini. Penting untuk mempertimbangkan metadata yang terlampir pada gambar, seperti label gambar. Salah satu solusi adalah menyandikan label ke dalam nama gambar, namun ini memaksa kita untuk menangani semua file saat melakukan sesuatu dengan label. Alternatifnya, kita dapat menyimpan label dalam file terpisah, seperti file .csv. Hal ini memungkinkan kita untuk bermain-main dengan label tanpa harus memuat gambar.

## Storing to LMDB

LMDB adalah sistem penyimpanan kunci-nilai di mana setiap entri disimpan sebagai larik byte, sehingga dalam kasus kita, kunci akan menjadi pengidentifikasi unik untuk setiap gambar, dan nilai akan menjadi gambar itu sendiri. Baik kunci maupun nilai diharapkan berupa string, jadi penggunaan umum adalah untuk meng-serialize nilai sebagai string, dan kemudian mengunserialize-nya saat membacanya kembali.

Kita dapat menggunakan pickle untuk proses serializing. Setiap objek Python dapat di-serialize, jadi sebaiknya kita juga menyertakan meta data gambar dalam database. Ini menghemat kita dari kesulitan menambahkan kembali meta data ke data gambar saat kita memuat dataset dari disk.

Kita dapat membuat kelas dasar Python untuk gambar dan meta datanya:


```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Pertama, LMDB memerlukan penyesuaian ukuran memori yang diharapkan untuk digunakan oleh database baru, yang disebut sebagai map_size. Ini penting untuk diperhatikan agar LMDB dapat beroperasi dengan optimal. Misalnya, dalam kasus kami, penyesuaian ini cukup mudah, tetapi dapat menjadi masalah besar dalam kasus lain yang akan dibahas lebih lanjut di bagian selanjutnya.

Kedua, operasi baca dan tulis dengan LMDB dilakukan dalam transaksi. Transaksi ini mirip dengan transaksi pada database tradisional, terdiri dari sekelompok operasi pada database. Meskipun ini mungkin terlihat lebih rumit daripada versi penyimpanan di disk, namun tetap bisa dipahami dengan membaca lebih lanjut.


```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

## Storing With HDF5

Ketika menggunakan file HDF5, penting untuk diingat bahwa satu file dapat berisi lebih dari satu dataset. Dalam kasus ini, kita dapat membuat dua dataset: satu untuk gambar dan satu untuk metadata gambar. Hal ini memungkinkan kita untuk menyimpan informasi gambar dan metadata terkait secara terpisah namun dalam satu file, memudahkan pengelolaan dan pemrosesan data.


```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

## Experiments for Storing a Single Image


```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```


```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.0037444999907165766
    Method: lmdb, Time usage: 0.006498500006273389
    Method: hdf5, Time usage: 0.0069435999903362244


Dari hasil diatas, jika kecepatan eksekusi adalah faktor utama, metode "disk" mungkin menjadi pilihan yang lebih baik. Namun, untuk kasus penggunaan tertentu di mana skala dan manajemen data yang lebih kompleks diperlukan, metode "lmdb" dan "hdf5" mungkin menawarkan keuntungan lain seperti manajemen data yang lebih baik.

## Storing Many Images

Jadi, untuk menyimpan banyak gambar, kita perlu menyesuaikan kode agar dapat menangani kasus tersebut. Untuk menyimpan gambar sebagai file .png, kita hanya perlu memanggil fungsi store_single_method() beberapa kali. Namun, hal ini tidak berlaku untuk LMDB atau HDF5, karena kita tidak ingin memiliki file database yang berbeda untuk setiap gambar. Sebaliknya, kita ingin menyimpan semua gambar ke dalam satu atau lebih file.

Kita perlu sedikit mengubah kode dan membuat tiga fungsi baru yang menerima beberapa gambar sekaligus, yaitu store_many_disk(), store_many_lmdb(), dan store_many_hdf5(). Dengan demikian, kita dapat menyimpan banyak gambar dengan efisien dan terorganisir, baik dalam format file disk, LMDB, maupun HDF5.


```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

## Preparing the Dataset

Mari kita persiapkan dataset dengan menambahkan ukuran dataset kita menjadi dua kali lipat sehingga kita dapat menguji dengan hingga 100.000 gambar:


```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

    (100000, 32, 32, 3)
    (100000,)


## Experiment for Storing Many Images

Dalam eksperimen kami, kami menyimpan banyak gambar menggunakan metode penyimpanan ke disk, LMDB, dan HDF5. Kami menggunakan timeit untuk mengukur waktu penyimpanan gambar pada setiap metode. Hasil eksperimen akan disajikan dalam visualisasi grafik untuk membandingkan waktu penyimpanan gambar dengan berbagai metode.


```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.035630400001537055
    Method: lmdb, Time usage: 0.008798100025160238
    Method: hdf5, Time usage: 0.0044732999813277274
    Method: disk, Time usage: 0.3950958999921568
    Method: lmdb, Time usage: 0.02046989998780191
    Method: hdf5, Time usage: 0.004531799990218133
    Method: disk, Time usage: 2.375462099997094
    Method: lmdb, Time usage: 0.09996510000200942
    Method: hdf5, Time usage: 0.00835779999033548
    Method: disk, Time usage: 26.98022120000678
    Method: lmdb, Time usage: 0.8977929000102449
    Method: hdf5, Time usage: 0.07389679999323562
    Method: disk, Time usage: 257.07229010001174
    Method: lmdb, Time usage: 6.789313700021012
    Method: hdf5, Time usage: 1.171017300017411


Metode penyimpanan yang diuji pada penelitian ini mencoba menyimpan 111110 gambar, masing-masing disimpan sebanyak 5 kali. Hasilnya menunjukkan bahwa metode penyimpanan menggunakan format HDF5 memiliki waktu penggunaan paling cepat di antara ketiga metode yang diuji. Hal ini menyarankan bahwa format HDF5 sangat cocok untuk aplikasi yang membutuhkan operasi pembacaan data gambar yang cepat dan efisien.

Metode pembacaan dari LMDB juga menunjukkan kinerja yang baik dengan waktu penggunaan yang lebih cepat daripada pembacaan langsung dari disk. Oleh karena itu, LMDB bisa menjadi pilihan yang baik jika aplikasi memerlukan penyimpanan data gambar dalam bentuk basis data berorientasi key-value dengan kinerja yang tinggi.

Di sisi lain, pembacaan langsung dari disk menunjukkan waktu penggunaan yang lebih lambat dibandingkan dengan metode lainnya. Namun, metode ini masih dapat dipertimbangkan jika aplikasi memiliki keterbatasan dalam penggunaan sumber daya tambahan seperti basis data, atau jika skala data yang dikelola tidak terlalu besar.


```python
! pip install matplotlib
```

    Collecting matplotlib
      Downloading matplotlib-3.8.4-cp310-cp310-win_amd64.whl (7.7 MB)
         ---------------------------------------- 7.7/7.7 MB 1.4 MB/s eta 0:00:00
    Requirement already satisfied: packaging>=20.0 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib) (21.3)
    Requirement already satisfied: python-dateutil>=2.7 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib) (2.8.2)
    Collecting contourpy>=1.0.1
      Downloading contourpy-1.2.1-cp310-cp310-win_amd64.whl (187 kB)
         -------------------------------------- 187.5/187.5 kB 1.9 MB/s eta 0:00:00
    Collecting fonttools>=4.22.0
      Downloading fonttools-4.51.0-cp310-cp310-win_amd64.whl (2.2 MB)
         ---------------------------------------- 2.2/2.2 MB 2.6 MB/s eta 0:00:00
    Collecting cycler>=0.10
      Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
    Collecting kiwisolver>=1.3.1
      Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)
         -------------------------------------- 56.1/56.1 kB 975.6 kB/s eta 0:00:00
    Requirement already satisfied: pillow>=8 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib) (10.3.0)
    Requirement already satisfied: numpy>=1.21 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib) (1.26.4)
    Requirement already satisfied: pyparsing>=2.3.1 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib) (3.0.9)
    Requirement already satisfied: six>=1.5 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)
    Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib
    Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 kiwisolver-1.4.5 matplotlib-3.8.4


    
    [notice] A new release of pip is available: 23.0.1 -> 24.0
    [notice] To update, run: python.exe -m pip install --upgrade pip



```python
! pip install seaborn
```

    Requirement already satisfied: seaborn in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (0.13.2)
    Requirement already satisfied: pandas>=1.2 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from seaborn) (2.2.2)
    Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from seaborn) (1.26.4)
    Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from seaborn) (3.8.4)
    Requirement already satisfied: contourpy>=1.0.1 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)
    Requirement already satisfied: kiwisolver>=1.3.1 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)
    Requirement already satisfied: pyparsing>=2.3.1 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)
    Requirement already satisfied: pillow>=8 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)
    Requirement already satisfied: python-dateutil>=2.7 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)
    Requirement already satisfied: fonttools>=4.22.0 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)
    Requirement already satisfied: cycler>=0.10 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)
    Requirement already satisfied: packaging>=20.0 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)
    Requirement already satisfied: tzdata>=2022.7 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from pandas>=1.2->seaborn) (2024.1)
    Requirement already satisfied: pytz>=2020.1 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from pandas>=1.2->seaborn) (2022.2.1)
    Requirement already satisfied: six>=1.5 in c:\users\hermalina\appdata\local\programs\python\python310\lib\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)


    
    [notice] A new release of pip is available: 23.0.1 -> 24.0
    [notice] To update, run: python.exe -m pip install --upgrade pip



```python
import matplotlib.pyplot as plt
print(plt.style.available)

```

    ['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']



```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("ggplot")  # Menggunakan gaya "ggplot"
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Mendapatkan data waktu penyimpanan untuk ditampilkan
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```


    
![png](RC-121450052_files/RC-121450052_39_0.png)
    



    
![png](RC-121450052_files/RC-121450052_39_1.png)
    


Grafik tersebut menampilkan tiga kurva yang mewakili waktu yang diperlukan untuk menyimpan gambar menggunakan tiga metode penyimpanan yang berbeda: disk, LMDB, dan HDF5. Setiap kurva menunjukkan bagaimana waktu penyimpanan bervariasi dengan jumlah gambar yang disimpan, mulai dari satu gambar hingga 100.000 gambar.

Metode Disk: Kurva untuk metode penyimpanan disk menunjukkan peningkatan waktu penyimpanan yang hampir linear seiring dengan peningkatan jumlah gambar. Pada awalnya, waktu penyimpanan metode disk relatif cepat dibandingkan dengan metode LMDB dan HDF5, terutama untuk jumlah gambar yang kecil. Namun, ketika jumlah gambar meningkat, waktu penyimpanan metode disk menjadi yang paling lambat di antara ketiga metode.

Metode LMDB: Kurva untuk metode penyimpanan LMDB menunjukkan peningkatan waktu penyimpanan yang lebih lambat daripada metode disk pada jumlah gambar yang lebih kecil. Namun, pada jumlah gambar yang besar, waktu penyimpanan metode LMDB menjadi lebih cepat daripada metode disk. Hal ini menunjukkan bahwa metode LMDB lebih efisien untuk menyimpan gambar dalam jumlah besar.

Metode HDF5: Kurva untuk metode penyimpanan HDF5 menunjukkan peningkatan waktu penyimpanan yang paling lambat di antara ketiga metode, baik untuk jumlah gambar kecil maupun besar. Hal ini menunjukkan bahwa metode HDF5 adalah yang paling lambat di antara ketiga metode untuk menyimpan gambar.

## Reading a Single Image

####  Reading From Disk


```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

#### Reading From LMDB


```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

#### Reading From HDF5


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

### Experiment for Reading a Single Image


```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.002495900000212714
    Method: lmdb, Time usage: 0.0012655000027734786
    Method: hdf5, Time usage: 0.004390099988086149


## Reading Many Images


```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

### Experiment for Reading Many Images


```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=0,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

    Method: disk, No. images: 10, Time usage: 7.00005330145359e-07
    Method: lmdb, No. images: 10, Time usage: 6.999762263149023e-07
    Method: hdf5, No. images: 10, Time usage: 7.00005330145359e-07
    Method: disk, No. images: 100, Time usage: 9.00006853044033e-07
    Method: lmdb, No. images: 100, Time usage: 7.999769877642393e-07
    Method: hdf5, No. images: 100, Time usage: 8.00006091594696e-07
    Method: disk, No. images: 1000, Time usage: 1.00000761449337e-06
    Method: lmdb, No. images: 1000, Time usage: 8.00006091594696e-07
    Method: hdf5, No. images: 1000, Time usage: 1.00000761449337e-06
    Method: disk, No. images: 10000, Time usage: 7.00005330145359e-07
    Method: lmdb, No. images: 10000, Time usage: 6.00004568696022e-07
    Method: hdf5, No. images: 10000, Time usage: 7.00005330145359e-07
    Method: disk, No. images: 100000, Time usage: 8.00006091594696e-07
    Method: lmdb, No. images: 100000, Time usage: 1.5999830793589354e-06
    Method: hdf5, No. images: 100000, Time usage: 1.400010660290718e-06



```python
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
```


    
![png](RC-121450052_files/RC-121450052_55_0.png)
    



    
![png](RC-121450052_files/RC-121450052_55_1.png)
    


Grafik menunjukkan bahwa rata-rata waktu baca untuk metode penyimpanan disk cenderung tetap stabil meskipun jumlah gambar yang dibaca meningkat. Namun, untuk metode LMDB dan HDF5, rata-rata waktu baca sedikit meningkat seiring dengan peningkatan jumlah gambar. Meskipun demikian, peningkatan ini mungkin tidak begitu signifikan.


```python
plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r, disk_x, lmdb_x, hdf5_x],
    [
        "Read PNG",
        "Read LMDB",
        "Read HDF5",
        "Write PNG",
        "Write LMDB",
        "Write HDF5",
    ],
    "Number of images",
    "Seconds",
    "Log Store and Read Times",
    log=False,
)
```


    
![png](RC-121450052_files/RC-121450052_57_0.png)
    



```python
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]

X = [disk_mem, lmdb_mem, hdf5_mem]

ind = np.arange(3)
width = 0.35

plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )

plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))

plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```


    
![png](RC-121450052_files/RC-121450052_58_0.png)
    


Berdasarkan hasil pengukuran yang terlihat dalam grafik, ketiga metode penyimpanan tersebut menunjukkan kemampuan untuk membaca dan menulis gambar dengan waktu yang singkat dan konsisten, bahkan ketika jumlah gambar yang disimpan cukup besar.

Metode Disk menunjukkan konsistensi waktu baca dan tulis yang baik, terutama saat digunakan untuk membaca dan menulis sedikit gambar. Metode LMDB, secara keseluruhan, menampilkan waktu baca dan tulis yang sedikit lebih cepat daripada Metode Disk. Sedangkan Metode HDF5, meskipun memiliki waktu baca dan tulis yang sedikit lebih lambat dibandingkan Metode LMDB dan Disk, tetap menunjukkan kinerja yang cepat dan konsisten.
